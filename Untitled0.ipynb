{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":479,"status":"ok","timestamp":1710940640681,"user":{"displayName":"peddisetti mahesh","userId":"05717867753691821196"},"user_tz":-330},"id":"xkYpLrpv56Wn"},"outputs":[],"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","import random\n","import numpy as np\n","from glob import glob\n","from PIL import Image, ImageOps\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from keras import layers\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"eFxcR-M96Jyd"},"source":["Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":426,"status":"ok","timestamp":1710940748181,"user":{"displayName":"peddisetti mahesh","userId":"05717867753691821196"},"user_tz":-330},"id":"JMhrO6F-6AbA","outputId":"1c46bd05-5b69-4948-aacc-ff882d25ed93"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: <_BatchDataset element_spec=TensorSpec(shape=(16, 256, 256, 3), dtype=tf.float32, name=None)>\n","Validation Dataset: <_BatchDataset element_spec=TensorSpec(shape=(16, 256, 256, 3), dtype=tf.float32, name=None)>\n"]}],"source":["# IMAGE_SIZE = 256\n","# BATCH_SIZE = 16\n","# MAX_TRAIN_IMAGES = 400\n","\n","# def load_data(image_path):\n","#     image = tf.io.read_file(image_path)\n","#     image = tf.image.decode_png(image, channels=3)\n","#     image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n","#     image = image / 255.0\n","#     return image\n","\n","\n","# def data_generator(low_light_images):\n","#     dataset = tf.data.Dataset.from_tensor_slices((low_light_images))\n","#     dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n","#     dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","#     return dataset\n","\n","\n","# # train_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[:MAX_TRAIN_IMAGES]\n","# # val_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[MAX_TRAIN_IMAGES:]\n","# # test_low_light_images = sorted(glob(\"./lol_dataset/eval15/low/*\"))\n","# train_low_light_images = sorted(glob(\"./content/drive/MyDrive/Colab Notebooks/Low_Light/LOLdataset/our485/low/*\"))[:MAX_TRAIN_IMAGES]\n","# val_low_light_images = sorted(glob(\"/.content/drive/MyDrive/Colab Notebooks/Low_Light/LOLdataset/our485/low/*\"))[MAX_TRAIN_IMAGES:]\n","# test_low_light_images = sorted(glob(\"./content/drive/MyDrive/Colab Notebooks/Low_Light/LOLdataset/eval15/low*\"))\n","\n","\n","# train_dataset = data_generator(train_low_light_images)\n","# val_dataset = data_generator(val_low_light_images)\n","\n","# print(\"Train Dataset:\", train_dataset)\n","# print(\"Validation Dataset:\", val_dataset)\n","\n","import tensorflow as tf\n","from glob import glob\n","\n","IMAGE_SIZE = 256\n","BATCH_SIZE = 16\n","MAX_TRAIN_IMAGES = 400\n","\n","def load_data(image_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_png(image, channels=3)\n","    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n","    image = image / 255.0\n","    return image\n","\n","def data_generator(image_paths):\n","    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n","    # print(type(dataset))\n","    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","    return dataset\n","\n","# train_low_light_images = sorted(glob(\"/content/drive/MyDrive/Colab Notebooks/Low_Light/LOLdataset/our485/low//*\"))[:MAX_TRAIN_IMAGES]\n","# val_low_light_images = sorted(glob(\"/content/drive/MyDrive/Colab Notebooks/Low_Light/LOLdataset/our485/low//*\"))[MAX_TRAIN_IMAGES:]\n","# test_low_light_images = sorted(glob(\"/content/drive/MyDrive/Colab Notebooks/Low_Light/LOLdataset/eval15/low//*\"))\n","\n","train_low_light_images = sorted(glob(\"C:\\Low Light\\LOLdataset\\our485\\low//*\"))[:MAX_TRAIN_IMAGES]\n","val_low_light_images = sorted(glob(\"C:\\Low Light\\LOLdataset\\our485\\low//*\"))[MAX_TRAIN_IMAGES:]\n","test_low_light_images = sorted(glob(\"C:\\Low Light\\LOLdataset\\eval15\\low//*\"))\n","# print(glob(\"/content/drive/MyDrive/Colab Notebooks/Low_Light/LOLdataset/our485/low//*\"))\n","# print(train_low_light_images)\n","\n","train_dataset = data_generator(train_low_light_images)\n","val_dataset = data_generator(val_low_light_images)\n","\n","print(\"Train Dataset:\", train_dataset)\n","print(\"Validation Dataset:\", val_dataset)\n"]},{"cell_type":"markdown","metadata":{"id":"e222KCEl6Q5h"},"source":["Zero-DCE Framework"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":439,"status":"ok","timestamp":1710940753952,"user":{"displayName":"peddisetti mahesh","userId":"05717867753691821196"},"user_tz":-330},"id":"KC7q4Cmr6Amt"},"outputs":[],"source":["def build_dce_net():\n","    input_img = keras.Input(shape=[None, None, 3])\n","    conv1 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(input_img)\n","    conv2 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(conv1)\n","    conv3 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(conv2)\n","    conv4 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(conv3)\n","    int_con1 = layers.Concatenate(axis=-1)([conv4, conv3])\n","    conv5 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(int_con1)\n","    int_con2 = layers.Concatenate(axis=-1)([conv5, conv2])\n","    conv6 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(int_con2)\n","    int_con3 = layers.Concatenate(axis=-1)([conv6, conv1])\n","    x_r = layers.Conv2D(24, (3, 3), strides=(1, 1), activation=\"tanh\", padding=\"same\")(\n","        int_con3\n","    )\n","    return keras.Model(inputs=input_img, outputs=x_r)"]},{"cell_type":"markdown","metadata":{"id":"xld00Kj46Vil"},"source":["LOSS FUNCTION"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":381,"status":"ok","timestamp":1710940758902,"user":{"displayName":"peddisetti mahesh","userId":"05717867753691821196"},"user_tz":-330},"id":"SLpaicR56Apt"},"outputs":[],"source":["def color_constancy_loss(x):\n","    mean_rgb = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n","    mr, mg, mb = (\n","        mean_rgb[:, :, :, 0],\n","        mean_rgb[:, :, :, 1],\n","        mean_rgb[:, :, :, 2],\n","    )\n","    d_rg = tf.square(mr - mg)\n","    d_rb = tf.square(mr - mb)\n","    d_gb = tf.square(mb - mg)\n","    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))"]},{"cell_type":"markdown","metadata":{"id":"uK7nNBa66aB8"},"source":["Exposure Loss"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710940761316,"user":{"displayName":"peddisetti mahesh","userId":"05717867753691821196"},"user_tz":-330},"id":"J71ws-fa6As1"},"outputs":[],"source":["def exposure_loss(x, mean_val=0.6):\n","    x = tf.reduce_mean(x, axis=3, keepdims=True)\n","    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding=\"VALID\")\n","    return tf.reduce_mean(tf.square(mean - mean_val))"]},{"cell_type":"markdown","metadata":{"id":"XEgCO-CX6flo"},"source":["Illumination smooth loss"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710940764340,"user":{"displayName":"peddisetti mahesh","userId":"05717867753691821196"},"user_tz":-330},"id":"0jrWiWIF6AwZ"},"outputs":[],"source":["def illumination_smoothness_loss(x):\n","    batch_size = tf.shape(x)[0]\n","    h_x = tf.shape(x)[1]\n","    w_x = tf.shape(x)[2]\n","    count_h = (tf.shape(x)[2] - 1) * tf.shape(x)[3]\n","    count_w = tf.shape(x)[2] * (tf.shape(x)[3] - 1)\n","    h_tv = tf.reduce_sum(tf.square((x[:, 1:, :, :] - x[:, : h_x - 1, :, :])))\n","    w_tv = tf.reduce_sum(tf.square((x[:, :, 1:, :] - x[:, :, : w_x - 1, :])))\n","    batch_size = tf.cast(batch_size, dtype=tf.float32)\n","    count_h = tf.cast(count_h, dtype=tf.float32)\n","    count_w = tf.cast(count_w, dtype=tf.float32)\n","    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size"]},{"cell_type":"markdown","metadata":{"id":"aepAjijl6ko8"},"source":["Spatial Consistency loss"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1710940767895,"user":{"displayName":"peddisetti mahesh","userId":"05717867753691821196"},"user_tz":-330},"id":"Oj_gxKEn6Azk"},"outputs":[],"source":["class SpatialConsistencyLoss(keras.losses.Loss):\n","    def __init__(self, **kwargs):\n","        super().__init__(reduction=\"none\")\n","\n","        self.left_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.right_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.up_kernel = tf.constant(\n","            [[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.down_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32\n","        )\n","\n","    def call(self, y_true, y_pred):\n","        original_mean = tf.reduce_mean(y_true, 3, keepdims=True)\n","        enhanced_mean = tf.reduce_mean(y_pred, 3, keepdims=True)\n","        original_pool = tf.nn.avg_pool2d(\n","            original_mean, ksize=4, strides=4, padding=\"VALID\"\n","        )\n","        enhanced_pool = tf.nn.avg_pool2d(\n","            enhanced_mean, ksize=4, strides=4, padding=\"VALID\"\n","        )\n","\n","        d_original_left = tf.nn.conv2d(\n","            original_pool,\n","            self.left_kernel,\n","            strides=[1, 1, 1, 1],\n","            padding=\"SAME\",\n","        )\n","        d_original_right = tf.nn.conv2d(\n","            original_pool,\n","            self.right_kernel,\n","            strides=[1, 1, 1, 1],\n","            padding=\"SAME\",\n","        )\n","        d_original_up = tf.nn.conv2d(\n","            original_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_original_down = tf.nn.conv2d(\n","            original_pool,\n","            self.down_kernel,\n","            strides=[1, 1, 1, 1],\n","            padding=\"SAME\",\n","        )\n","\n","        d_enhanced_left = tf.nn.conv2d(\n","            enhanced_pool,\n","            self.left_kernel,\n","            strides=[1, 1, 1, 1],\n","            padding=\"SAME\",\n","        )\n","        d_enhanced_right = tf.nn.conv2d(\n","            enhanced_pool,\n","            self.right_kernel,\n","            strides=[1, 1, 1, 1],\n","            padding=\"SAME\",\n","        )\n","        d_enhanced_up = tf.nn.conv2d(\n","            enhanced_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_enhanced_down = tf.nn.conv2d(\n","            enhanced_pool,\n","            self.down_kernel,\n","            strides=[1, 1, 1, 1],\n","            padding=\"SAME\",\n","        )\n","\n","        d_left = tf.square(d_original_left - d_enhanced_left)\n","        d_right = tf.square(d_original_right - d_enhanced_right)\n","        d_up = tf.square(d_original_up - d_enhanced_up)\n","        d_down = tf.square(d_original_down - d_enhanced_down)\n","        return d_left + d_right + d_up + d_down"]},{"cell_type":"markdown","metadata":{"id":"tV9qZ3Di6o74"},"source":["Deep curve estimation model"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":641,"status":"ok","timestamp":1710940771946,"user":{"displayName":"peddisetti mahesh","userId":"05717867753691821196"},"user_tz":-330},"id":"H4mPniZI6A3H"},"outputs":[],"source":["class ZeroDCE(keras.Model):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.dce_model = build_dce_net()\n","\n","    def compile(self, learning_rate, **kwargs):\n","        super().compile(**kwargs)\n","        self.optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","        self.spatial_constancy_loss = SpatialConsistencyLoss(reduction=\"none\")\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n","        self.illumination_smoothness_loss_tracker = keras.metrics.Mean(\n","            name=\"illumination_smoothness_loss\"\n","        )\n","        self.spatial_constancy_loss_tracker = keras.metrics.Mean(\n","            name=\"spatial_constancy_loss\"\n","        )\n","        self.color_constancy_loss_tracker = keras.metrics.Mean(\n","            name=\"color_constancy_loss\"\n","        )\n","        self.exposure_loss_tracker = keras.metrics.Mean(name=\"exposure_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.illumination_smoothness_loss_tracker,\n","            self.spatial_constancy_loss_tracker,\n","            self.color_constancy_loss_tracker,\n","            self.exposure_loss_tracker,\n","        ]\n","\n","    def get_enhanced_image(self, data, output):\n","        r1 = output[:, :, :, :3]\n","        r2 = output[:, :, :, 3:6]\n","        r3 = output[:, :, :, 6:9]\n","        r4 = output[:, :, :, 9:12]\n","        r5 = output[:, :, :, 12:15]\n","        r6 = output[:, :, :, 15:18]\n","        r7 = output[:, :, :, 18:21]\n","        r8 = output[:, :, :, 21:24]\n","        x = data + r1 * (tf.square(data) - data)\n","        x = x + r2 * (tf.square(x) - x)\n","        x = x + r3 * (tf.square(x) - x)\n","        enhanced_image = x + r4 * (tf.square(x) - x)\n","        x = enhanced_image + r5 * (tf.square(enhanced_image) - enhanced_image)\n","        x = x + r6 * (tf.square(x) - x)\n","        x = x + r7 * (tf.square(x) - x)\n","        enhanced_image = x + r8 * (tf.square(x) - x)\n","        return enhanced_image\n","\n","    def call(self, data):\n","        dce_net_output = self.dce_model(data)\n","        return self.get_enhanced_image(data, dce_net_output)\n","\n","    def compute_losses(self, data, output):\n","        enhanced_image = self.get_enhanced_image(data, output)\n","        loss_illumination = 200 * illumination_smoothness_loss(output)\n","        loss_spatial_constancy = tf.reduce_mean(\n","            self.spatial_constancy_loss(enhanced_image, data)\n","        )\n","        loss_color_constancy = 5 * tf.reduce_mean(color_constancy_loss(enhanced_image))\n","        loss_exposure = 10 * tf.reduce_mean(exposure_loss(enhanced_image))\n","        total_loss = (\n","            loss_illumination\n","            + loss_spatial_constancy\n","            + loss_color_constancy\n","            + loss_exposure\n","        )\n","\n","        return {\n","            \"total_loss\": total_loss,\n","            \"illumination_smoothness_loss\": loss_illumination,\n","            \"spatial_constancy_loss\": loss_spatial_constancy,\n","            \"color_constancy_loss\": loss_color_constancy,\n","            \"exposure_loss\": loss_exposure,\n","        }\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            output = self.dce_model(data)\n","            losses = self.compute_losses(data, output)\n","\n","        gradients = tape.gradient(\n","            losses[\"total_loss\"], self.dce_model.trainable_weights\n","        )\n","        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n","\n","        self.total_loss_tracker.update_state(losses[\"total_loss\"])\n","        self.illumination_smoothness_loss_tracker.update_state(\n","            losses[\"illumination_smoothness_loss\"]\n","        )\n","        self.spatial_constancy_loss_tracker.update_state(\n","            losses[\"spatial_constancy_loss\"]\n","        )\n","        self.color_constancy_loss_tracker.update_state(losses[\"color_constancy_loss\"])\n","        self.exposure_loss_tracker.update_state(losses[\"exposure_loss\"])\n","\n","        return {metric.name: metric.result() for metric in self.metrics}\n","\n","    def test_step(self, data):\n","        output = self.dce_model(data)\n","        losses = self.compute_losses(data, output)\n","\n","        self.total_loss_tracker.update_state(losses[\"total_loss\"])\n","        self.illumination_smoothness_loss_tracker.update_state(\n","            losses[\"illumination_smoothness_loss\"]\n","        )\n","        self.spatial_constancy_loss_tracker.update_state(\n","            losses[\"spatial_constancy_loss\"]\n","        )\n","        self.color_constancy_loss_tracker.update_state(losses[\"color_constancy_loss\"])\n","        self.exposure_loss_tracker.update_state(losses[\"exposure_loss\"])\n","\n","        return {metric.name: metric.result() for metric in self.metrics}\n","\n","    def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n","        \"\"\"While saving the weights, we simply save the weights of the DCE-Net\"\"\"\n","        self.dce_model.save_weights(\n","            filepath,\n","            overwrite=overwrite,\n","            save_format=save_format,\n","            options=options,\n","        )\n","\n","    def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n","        \"\"\"While loading the weights, we simply load the weights of the DCE-Net\"\"\"\n","        self.dce_model.load_weights(\n","            filepath=filepath,\n","            by_name=by_name,\n","            skip_mismatch=skip_mismatch,\n","            options=options,\n","        )"]},{"cell_type":"markdown","metadata":{"id":"MdkOrla36uQn"},"source":["Training"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YVdCz55K6BA3"},"outputs":[{"ename":"NameError","evalue":"name 'ZeroDCE' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m zero_dce_model \u001b[38;5;241m=\u001b[39m \u001b[43mZeroDCE\u001b[49m()\n\u001b[0;32m      2\u001b[0m zero_dce_model\u001b[38;5;241m.\u001b[39mcompile(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m      3\u001b[0m history \u001b[38;5;241m=\u001b[39m zero_dce_model\u001b[38;5;241m.\u001b[39mfit(train_dataset, validation_data\u001b[38;5;241m=\u001b[39mval_dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'ZeroDCE' is not defined"]}],"source":["zero_dce_model = ZeroDCE()\n","zero_dce_model.compile(learning_rate=1e-4)\n","history = zero_dce_model.fit(train_dataset, validation_data=val_dataset, epochs=100)\n","def plot_result(item):\n","    plt.plot(history.history[item], label=item)\n","    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(item)\n","    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n","    plt.legend()\n","    plt.grid()\n","    plt.show()\n","plot_result(\"total_loss\")\n","plot_result(\"illumination_smoothness_loss\")\n","plot_result(\"spatial_constancy_loss\")\n","plot_result(\"color_constancy_loss\")\n","plot_result(\"exposure_loss\")"]},{"cell_type":"markdown","metadata":{"id":"8ADcVWwB60vl"},"source":["Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xs7ONgAQ6BDq"},"outputs":[],"source":["def plot_results(images, titles, figure_size=(12, 12)):\n","    fig = plt.figure(figsize=figure_size)\n","    for i in range(len(images)):\n","        fig.add_subplot(1, len(images), i + 1).set_title(titles[i])\n","        _ = plt.imshow(images[i])\n","        plt.axis(\"off\")\n","    plt.show()\n","\n","\n","def infer(original_image):\n","    image = keras.utils.img_to_array(original_image)\n","    image = image.astype(\"float32\") / 255.0\n","    image = np.expand_dims(image, axis=0)\n","    output_image = zero_dce_model(image)\n","    output_image = tf.cast((output_image[0, :, :, :] * 255), dtype=np.uint8)\n","    output_image = Image.fromarray(output_image.numpy())\n","    return output_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UA8WmEGB6BHH"},"outputs":[],"source":["for val_image_file in test_low_light_images:\n","    original_image = Image.open(val_image_file)\n","    enhanced_image = infer(original_image)\n","    plot_results(\n","        [original_image, ImageOps.autocontrast(original_image), enhanced_image],\n","        [\"Original\", \"PIL Autocontrast\", \"Enhanced\"],\n","        (20, 12),\n","    )"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"H30WsBRJ6BPO"},"outputs":[{"ename":"TypeError","evalue":"Could not locate class 'ZeroDCE'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': None, 'class_name': 'ZeroDCE', 'config': {'name': 'zero_dce', 'trainable': True, 'dtype': 'float32'}, 'registered_name': 'ZeroDCE', 'build_config': {'input_shape': [1, 400, 600, 3]}, 'compile_config': {'optimizer': 'rmsprop', 'loss': None, 'metrics': None, 'loss_weights': None, 'weighted_metrics': None, 'run_eagerly': None, 'steps_per_execution': None, 'jit_compile': None}}","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLow Light\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Check model summary\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# loaded_model.summary()\u001b[39;00m\n\u001b[0;32m     46\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLow Light\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLOLdataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meval15\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_66666.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n","File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:155\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 155\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n","File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:687\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 687\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n","File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n","\u001b[1;31mTypeError\u001b[0m: Could not locate class 'ZeroDCE'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': None, 'class_name': 'ZeroDCE', 'config': {'name': 'zero_dce', 'trainable': True, 'dtype': 'float32'}, 'registered_name': 'ZeroDCE', 'build_config': {'input_shape': [1, 400, 600, 3]}, 'compile_config': {'optimizer': 'rmsprop', 'loss': None, 'metrics': None, 'loss_weights': None, 'weighted_metrics': None, 'run_eagerly': None, 'steps_per_execution': None, 'jit_compile': None}}"]}],"source":["# # Step 1: Import necessary libraries\n","# import tensorflow as tf\n","# from tensorflow import keras\n","\n","# # Step 2: Load the model\n","# model = keras.models.load_model('C:\\Low Light\\model.keras')  # Replace 'path_to_your_model.h5' with the actual path to your model file\n","\n","# # Step 3: Use the model\n","# # Example: Making predictions\n","# predictions = model.predict('C:\\Low Light\\LOLdataset\\eval15\\low\\_55555.png')  # Replace 'your_input_data' with the data you want to predict on\n","\n","# # Example: Getting model summary\n","# model.summary()\n","# Step 1: Import necessary libraries\n","# import tensorflow as tf\n","# from tensorflow import keras\n","# import numpy as np\n","\n","# # Step 2: Load the model\n","# model = keras.models.load_model(r'C:\\Low Light\\model.keras')  # Use either forward slashes or double backslashes for file path\n","\n","# Step 3: Use the model\n","# Example: Making predictions\n","# Load the image using appropriate libraries and preprocess it before passing to the model\n","# image = keras.preprocessing.image.load_img(r'C:\\Low Light\\LOLdataset\\eval15\\low\\_55555.png', target_size=(128, 128))\n","# input_arr = keras.preprocessing.image.img_to_array(image)\n","# input_arr = np.array([input_arr])  # Convert single image to a batch\n","# predictions = model.predict(input_arr)\n","\n","# # Example: Getting model summary\n","# model.summary()\n","\n","\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Path to the saved model directory\n","model_path = 'C:\\Low Light\\model.keras'\n","\n","# Load the model\n","loaded_model = keras.models.load_model(model_path)\n","\n","# Check model summary\n","# loaded_model.summary()\n","loaded_model.predict('C:\\Low Light\\LOLdataset\\eval15\\low\\_66666.png')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO+BMcDRkbU5P7xV4KQntMP","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
